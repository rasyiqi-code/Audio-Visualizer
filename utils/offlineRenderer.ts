/**
 * Offline Video Renderer
 * 
 * Method: Capture frames one-by-one (NOT real-time), then assemble with FFmpeg
 * 
 * Benefits:
 * - ‚úÖ ALL effects included (screenshot entire viewport)
 * - ‚úÖ NO timing issues (not real-time)
 * - ‚úÖ PERFECT quality (each frame captured perfectly)
 * - ‚úÖ NO corruption (no encoding pressure)
 * - ‚úÖ Guaranteed download
 */

import { FFmpeg } from '@ffmpeg/ffmpeg';
import { toBlobURL } from '@ffmpeg/util';

export interface OfflineRenderOptions {
  fps: number;
  duration: number; // in seconds
  width: number;
  height: number;
  audioBitrate?: number;
}

export class OfflineRenderer {
  private frames: Blob[] = [];
  private isRendering: boolean = false;
  private mainContainer: HTMLElement | null = null;

  constructor(container?: HTMLElement) {
    this.mainContainer = container || document.body;
    console.log('‚úÖ OfflineRenderer initialized with container:', this.mainContainer?.tagName, this.mainContainer?.className);
  }

  /**
   * Render video frame-by-frame (offline)
   */
  public async renderVideo(
    audioElement: HTMLAudioElement,
    options: OfflineRenderOptions,
    onProgress?: (progress: number, message: string) => void
  ): Promise<void> {
    if (!this.mainContainer) {
      console.error('‚ùå Main container not found!');
      throw new Error('Main container not found');
    }

    console.log('‚úÖ Main container verified:', this.mainContainer.tagName);

    this.isRendering = true;
    this.frames = [];

    const totalFrames = Math.ceil(options.duration * options.fps);
    const frameTime = 1 / options.fps;

    console.log(`üé¨ Starting offline render: ${totalFrames} frames @ ${options.fps} FPS`);
    onProgress?.(0, `Preparing to render ${totalFrames} frames...`);

    // Pause audio untuk manual control
    audioElement.pause();
    audioElement.currentTime = 0;

    // Force audio to play silently untuk trigger visualizer updates
    const originalVolume = audioElement.volume;
    audioElement.volume = 0;
    await audioElement.play();

    // Wait untuk audio context to be ready
    await new Promise(resolve => setTimeout(resolve, 500));

    // Render each frame dengan optimized timing
    for (let i = 0; i < totalFrames; i++) {
      if (!this.isRendering) break;

      // Set audio time untuk this frame
      const currentTime = i * frameTime;
      audioElement.currentTime = currentTime;

      // Reduced wait time untuk faster processing (20ms instead of 50ms)
      await new Promise(resolve => setTimeout(resolve, 20));

      // Capture frame
      try {
        const blob = await this.captureFrame(options.width, options.height);
        
        // Debug log untuk frame pertama dan setiap 60 frames
        if (i === 0 || i % 60 === 0) {
          console.log(`üéûÔ∏è Frame ${i + 1}: ${blob ? `${(blob.size/1024).toFixed(1)}KB` : '‚ùå NULL'}`);
        }
        
        if (blob) {
          this.frames.push(blob);
        } else {
          console.warn(`‚ö†Ô∏è Frame ${i + 1} capture returned NULL!`);
        }

        // Update progress more frequently
        const progress = ((i + 1) / totalFrames) * 50; // 0-50%
        if (i % 20 === 0 || i === totalFrames - 1) {
          onProgress?.(progress, `Rendering frame ${i + 1}/${totalFrames}`);
        }
      } catch (error) {
        console.error(`‚ùå Error capturing frame ${i}:`, error);
      }
    }

    // Restore audio
    audioElement.pause();
    audioElement.volume = originalVolume;
    audioElement.currentTime = 0;

    console.log(`‚úÖ All frames rendered: ${this.frames.length}/${totalFrames}`);
    
    // Validate frames
    if (this.frames.length === 0) {
      throw new Error('No frames captured! Check if canvases are rendering correctly.');
    }
    
    if (this.frames.length < totalFrames * 0.9) {
      console.warn(`‚ö†Ô∏è Only ${this.frames.length}/${totalFrames} frames captured (${Math.round(this.frames.length/totalFrames*100)}%)`);
    }
    
    onProgress?.(50, `All ${this.frames.length} frames captured! Preparing video assembly...`);
  }

  /**
   * Capture single frame dari main container
   */
  private async captureFrame(width: number, height: number): Promise<Blob | null> {
    if (!this.mainContainer) {
      console.error('‚ùå captureFrame: mainContainer is null');
      return null;
    }

    // Create temporary canvas
    const canvas = document.createElement('canvas');
    canvas.width = width;
    canvas.height = height;
    const ctx = canvas.getContext('2d');
    if (!ctx) {
      console.error('‚ùå captureFrame: failed to get 2d context');
      return null;
    }

    // Get all visible canvas elements sorted by z-index
    const allCanvases = Array.from(this.mainContainer.querySelectorAll('canvas'))
      .filter(canvas => {
        const style = window.getComputedStyle(canvas);
        if (style.display === 'none' || style.visibility === 'hidden') return false;
        if (canvas.width === 0 || canvas.height === 0) return false;
        
        // Include only visual elements (z-index <= 20)
        const zIndex = parseInt(style.zIndex) || 0;
        return zIndex <= 20;
      })
      .sort((a, b) => {
        const zA = parseInt(window.getComputedStyle(a).zIndex) || 0;
        const zB = parseInt(window.getComputedStyle(b).zIndex) || 0;
        return zA - zB;
      });

    // Get background color
    const bgColor = window.getComputedStyle(this.mainContainer).backgroundColor || '#000000';
    ctx.fillStyle = bgColor;
    ctx.fillRect(0, 0, width, height);

    // Draw each canvas layer
    for (const sourceCanvas of allCanvases) {
      try {
        const style = window.getComputedStyle(sourceCanvas);
        const blendMode = style.mixBlendMode || 'source-over';
        const opacity = parseFloat(style.opacity) || 1;

        ctx.save();
        ctx.globalCompositeOperation = blendMode as GlobalCompositeOperation;
        ctx.globalAlpha = opacity;
        ctx.drawImage(sourceCanvas, 0, 0, width, height);
        ctx.restore();
      } catch (error) {
        // Skip problematic canvas
      }
    }

    // Convert canvas to blob
    return new Promise(resolve => {
      canvas.toBlob(blob => resolve(blob), 'image/jpeg', 0.95);
    });
  }

  /**
   * Assemble frames + audio ke video dengan FFmpeg
   */
  public async assembleVideo(
    audioBlob: Blob,
    options: OfflineRenderOptions,
    outputFormat: 'mp4' | 'webm' = 'mp4',
    onProgress?: (progress: number, message: string) => void
  ): Promise<Blob> {
    if (this.frames.length === 0) {
      throw new Error('No frames to assemble');
    }

    console.log(`üé¨ Assembling ${this.frames.length} frames into video...`);
    onProgress?.(55, 'Loading FFmpeg...');

    const ffmpeg = new FFmpeg();

    try {
      // Load FFmpeg
      const baseURL = 'https://unpkg.com/@ffmpeg/core@0.12.6/dist/umd';
      await ffmpeg.load({
        coreURL: await toBlobURL(`${baseURL}/ffmpeg-core.js`, 'text/javascript'),
        wasmURL: await toBlobURL(`${baseURL}/ffmpeg-core.wasm`, 'application/wasm'),
      });
      
      onProgress?.(60, `Writing ${this.frames.length} frames...`);

      // Write frames to FFmpeg
      for (let i = 0; i < this.frames.length; i++) {
        const frameData = new Uint8Array(await this.frames[i].arrayBuffer());
        const fileName = `frame${String(i).padStart(6, '0')}.jpg`;
        await ffmpeg.writeFile(fileName, frameData);

        // Update progress
        if (i % 50 === 0) {
          const progress = 60 + ((i / this.frames.length) * 20);
          onProgress?.(progress, `Writing frames: ${i}/${this.frames.length}`);
        }
      }

      onProgress?.(80, 'Writing audio...');

      // Write audio
      const audioData = new Uint8Array(await audioBlob.arrayBuffer());
      await ffmpeg.writeFile('audio.webm', audioData);

      onProgress?.(85, 'Assembling video...');

      // Assemble video
      const outputFile = outputFormat === 'mp4' ? 'output.mp4' : 'output.webm';

      await ffmpeg.exec([
        '-framerate', options.fps.toString(),
        '-i', 'frame%06d.jpg',
        '-i', 'audio.webm',
        '-c:v', 'libx264',
        '-preset', 'medium',
        '-crf', '20', // Higher quality
        '-pix_fmt', 'yuv420p',
        '-c:a', 'aac',
        '-b:a', `${options.audioBitrate || 128}k`,
        '-shortest',
        '-movflags', '+faststart',
        outputFile
      ]);

      onProgress?.(95, 'Reading output...');

      // Read output
      const data = await ffmpeg.readFile(outputFile);
      const videoBlob = new Blob([data as unknown as BlobPart], {
        type: outputFormat === 'mp4' ? 'video/mp4' : 'video/webm'
      });

      onProgress?.(100, 'Complete!');
      console.log(`‚úÖ Video assembled: ${(videoBlob.size / 1024 / 1024).toFixed(2)} MB`);

      // Cleanup
      this.frames = [];

      return videoBlob;

    } catch (error) {
      console.error('Error assembling video:', error);
      throw new Error(`Failed to assemble video: ${(error as Error).message}`);
    }
  }

  /**
   * Stop rendering
   */
  public stopRendering(): void {
    this.isRendering = false;
  }

  /**
   * Get progress
   */
  public getFrameCount(): number {
    return this.frames.length;
  }
}

